# 通道 缓冲区
agent.channels = memoryChanne
# 消费者
agent.sinks = k
# 源数据生产者
agent.sources = sourceUdp sourceTcp

agent.channels.memoryChanne.type = memory
agent.channels.memoryChanne.capacity = 5000000

# elasticsearch
#agent.sinks.k.type = elasticsearch
#agent.sinks.k.client = rest
# elasticsearch 的配置路径加端口
#agent.sinks.k.hostNames = 127.0.0.1:9210
#agent.sinks.k.indexName = %{system_type}-%{module_type}-%{log_type}
#agent.sinks.k.indexType = doc
#agent.sinks.k.username = admin
#agent.sinks.k.password = admin
#agent.sinks.k.batchSize = 50
#agent.sinks.k.channel = memoryChanne


# kafka
agent.sinks.k.type = org.apache.flume.sink.kafka.KafkaSink
#设置kafka的主题topic
agent.sinks.k.topic = %{topic}
#设置kafka 的 broker地址以及端口号，多个 , 分开
agent.sinks.k.kafka.bootstrap.servers = 192.168.5.101:9092
agent.sinks.k.serializer.class = kafka.serializer.StringEncoder
agent.sinks.k.batchSize = 50
agent.sinks.k.channel = memoryChanne
auto.create.topics.enable = true

# udp
agent.sources.sourceUdp.type = cn.hba.audit.flume.source.syslog.UdpSyslogSource
agent.sources.sourceUdp.port = 514
agent.sources.sourceUdp.charset = utf8
# 本地的ip 地址
agent.sources.sourceUdp.host = 10.0.1.89
agent.sources.sourceUdp.keepFields = true
agent.sources.sourceUdp.channels = memoryChanne
agent.sources.sourceUdp.interceptors = jsinterceptor
agent.sources.sourceUdp.interceptors.jsinterceptor.type = cn.hba.audit.flume.soc.UdpSyslogParseInterceptor$Builder
# 是否为采集日志原始格式
agent.sources.sourceUdp.interceptors.jsinterceptor.isGatherLog = false
# 此处以 json 形式配置厂家对应设备ip,IP多个一‘,’隔开 例如：{'log_dp':'127.0.0.1,10.0.1.89'},此处的key对应
agent.sources.sourceUdp.interceptors.jsinterceptor.ipConfig = {'log_apt':'10.0.1.89','log_sxf':'192.168.3.10,192.168.83.7','log_h3c':'192.168.6.162,192.168.134.154,192.168.137.5,192.168.130.3,192.168.9.16,192.168.9.15,192.168.9.14,192.168.9.11,192.168.9.10,192.168.9.6,192.168.9.5,192.168.9.4,192.168.9.2,192.168.9.1,192.168.9.8,192.168.9.9,192.168.9.17,192.168.9.18,192.168.9.19,192.168.9.20,192.168.137.3','log_rs':'192.168.109.40,192.168.107.100,192.168.103.60,192.168.92.104,192.168.92.103,192.168.50.1,192.168.101.18,192.168.113.203','log_ws':'192.168.124.251','log_360':'192.168.131.9,192.168.131.12','log_kb':'192.168.6.115,192.168.6.114,192.168.134.117,192.168.134.116,192.168.134.115,192.168.134.114'}



# tcp
agent.sources.sourceTcp.type = cn.hba.audit.flume.source.syslog.MultiportSyslogTCPSource
agent.sources.sourceTcp.channels = memoryChanne
agent.sources.sourceTcp.host = 10.0.1.89
agent.sources.sourceTcp.ports = 10001 10002 1468
agent.sources.sourceTcp.portHeader = 1000
agent.sources.sourceTcp.charset = utf8
agent.sources.sourceTcp.interceptors = jsinterceptor
agent.sources.sourceTcp.interceptors.jsinterceptor.type = cn.hba.audit.flume.soc.TcpSyslogParseInterceptor$Builder
agent.sources.sourceTcp.interceptors.jsinterceptor.isGatherLog = false
agent.sources.sourceTcp.interceptors.jsinterceptor.ipConfig = {'log_apt':'192.168.81.203','log_sxf':'192.168.3.10,192.168.83.7','log_h3c':'192.168.6.162,192.168.134.154,192.168.137.5,192.168.130.3,192.168.9.16,192.168.9.15,192.168.9.14,192.168.9.11,192.168.9.10,192.168.9.6,192.168.9.5,192.168.9.4,192.168.9.2,192.168.9.1,192.168.9.8,192.168.9.9,192.168.9.17,192.168.9.18,192.168.9.19,192.168.9.20,192.168.137.3','log_rs':'192.168.109.40,192.168.107.100,192.168.103.60,192.168.92.104,192.168.92.103,192.168.50.1,192.168.101.18,192.168.113.203','log_ws':'192.168.124.251','log_360':'192.168.131.9,192.168.131.12','log_kb':'192.168.6.115,192.168.6.114,192.168.134.117,192.168.134.116,192.168.134.115,192.168.134.114'}
